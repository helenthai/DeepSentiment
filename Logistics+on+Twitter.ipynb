{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw = pd.read_csv(\"data/tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TweetId</th>\n",
       "      <th>TweetDate</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126415614616154112</td>\n",
       "      <td>Tue Oct 18 21:53:25 +0000 2011</td>\n",
       "      <td>Now all @Apple has to do is get swype on the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126402758403305474</td>\n",
       "      <td>Tue Oct 18 21:02:20 +0000 2011</td>\n",
       "      <td>Hilarious @youtube video - guy does a duet wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126397179614068736</td>\n",
       "      <td>Tue Oct 18 20:40:10 +0000 2011</td>\n",
       "      <td>@RIM you made it too easy for me to switch to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126379685453119488</td>\n",
       "      <td>Tue Oct 18 19:30:39 +0000 2011</td>\n",
       "      <td>The 16 strangest things Siri has said so far. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126377656416612353</td>\n",
       "      <td>Tue Oct 18 19:22:35 +0000 2011</td>\n",
       "      <td>Great up close &amp; personal event @Apple tonight...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic Sentiment             TweetId                       TweetDate  \\\n",
       "0  apple  positive  126415614616154112  Tue Oct 18 21:53:25 +0000 2011   \n",
       "1  apple  positive  126402758403305474  Tue Oct 18 21:02:20 +0000 2011   \n",
       "2  apple  positive  126397179614068736  Tue Oct 18 20:40:10 +0000 2011   \n",
       "3  apple  positive  126379685453119488  Tue Oct 18 19:30:39 +0000 2011   \n",
       "4  apple  positive  126377656416612353  Tue Oct 18 19:22:35 +0000 2011   \n",
       "\n",
       "                                           TweetText  \n",
       "0  Now all @Apple has to do is get swype on the i...  \n",
       "1  Hilarious @youtube video - guy does a duet wit...  \n",
       "2  @RIM you made it too easy for me to switch to ...  \n",
       "3  The 16 strangest things Siri has said so far. ...  \n",
       "4  Great up close & personal event @Apple tonight...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF + MNB (using movie review data as trainning data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to training set and testing set\n",
    "def review_series_to_list(review_series):\n",
    "    review_list=[]\n",
    "    n_review = len(review_series)\n",
    "    for i in range(0,n_review):\n",
    "        review_list.append(review_series[i])\n",
    "    return review_list  \n",
    "\n",
    "train_review_list = review_series_to_list(raw['TweetText'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_review_list, raw['Sentiment'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "nb_fit = nb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model_bow = Pipeline([('vect', CountVectorizer()),\n",
    "                    \n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "nb_fit_bow = nb_model_bow.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_predicted2 = nb_model_bow.predict(X_test)\n",
    "nb_accuracy2 = np.mean(nb_predicted2 == y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.697032436163\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.98      0.77      0.86       460\n",
      "   negative       0.00      0.00      0.00       184\n",
      "    neutral       0.60      0.99      0.75       661\n",
      "   positive       0.00      0.00      0.00       144\n",
      "\n",
      "avg / total       0.59      0.70      0.62      1449\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helen/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[354,   0, 106,   0],\n",
       "       [  0,   0, 184,   0],\n",
       "       [  5,   0, 656,   0],\n",
       "       [  1,   0, 143,   0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Prediction and evaluation\n",
    "nb_predicted = nb_model.predict(X_test)\n",
    "nb_accuracy = np.mean(nb_predicted == y_test) \n",
    "print (nb_accuracy)\n",
    "print(metrics.classification_report(y_test, nb_predicted)) \n",
    "metrics.confusion_matrix(y_test, nb_predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF + logistics (using movie review data as trainning data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "lr_model = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LR()),\n",
    "])\n",
    "\n",
    "lr_fit = lr_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.730158730159\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.94      0.81      0.87       460\n",
      "   negative       0.73      0.19      0.30       184\n",
      "    neutral       0.64      0.96      0.77       661\n",
      "   positive       0.88      0.10      0.19       144\n",
      "\n",
      "avg / total       0.77      0.73      0.68      1449\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[371,   2,  87,   0],\n",
       "       [  5,  35, 144,   0],\n",
       "       [ 13,   9, 637,   2],\n",
       "       [  4,   2, 123,  15]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_predicted = lr_model.predict(X_test)\n",
    "lr_accuracy = np.mean(lr_predicted == y_test) \n",
    "print (lr_accuracy)\n",
    "print(metrics.classification_report(y_test, lr_predicted))\n",
    "metrics.confusion_matrix(y_test, lr_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrl2_model = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LR(penalty = 'l2', dual = True, random_state = 0)),\n",
    "])\n",
    "\n",
    "lrl2_fit = lrl2_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.730158730159\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " irrelevant       0.94      0.81      0.87       460\n",
      "   negative       0.73      0.19      0.30       184\n",
      "    neutral       0.64      0.96      0.77       661\n",
      "   positive       0.88      0.10      0.19       144\n",
      "\n",
      "avg / total       0.77      0.73      0.68      1449\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[371,   2,  87,   0],\n",
       "       [  5,  35, 144,   0],\n",
       "       [ 13,   9, 637,   2],\n",
       "       [  4,   2, 123,  15]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrl2_predicted = lrl2_model.predict(X_test)\n",
    "lrl2_accuracy = np.mean(lrl2_predicted == y_test) \n",
    "print (lrl2_accuracy)\n",
    "print(metrics.classification_report(y_test, lr_predicted))\n",
    "metrics.confusion_matrix(y_test, lr_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.73728814,  0.73174873,  0.71938776,  0.75298126,  0.76109215])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores5 = model_selection.cross_val_score(lrl2_fit, X_train, y_train, cv=5)\n",
    "scores5   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_values = {'C':[30]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helen/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/helen/anaconda/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "model_LR = GridSearchCV(LR(penalty = 'l2', dual = True, random_state = 0), \n",
    "                        grid_values, scoring = 'roc_auc', cv = 20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## BOF + MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_words( raw_review ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    \n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    \n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_review) #revew_text \n",
    "    \n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    \n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    \n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return(\" \".join(meaningful_words ))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helen/anaconda/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/helen/anaconda/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "clean_review = review_to_words(raw[\"TweetText\"][0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helen/anaconda/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/helen/anaconda/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# Get the number of reviews based on the dataframe column size\n",
    "num_reviews = raw[\"TweetText\"].size\n",
    "\n",
    "# Initialize an empty list to hold the clean reviews\n",
    "clean_train_reviews = []\n",
    "\n",
    "# Loop over each review; create an index i that goes from 0 to the length\n",
    "# of the movie review list \n",
    "for i in range( 0, num_reviews ):\n",
    "    # Call our function for each one, and add the result to the list of\n",
    "    # clean reviews\n",
    "    clean_train_reviews.append( review_to_words( raw[\"TweetText\"][i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.42775882,  0.65642776,  0.71070615,  0.70125428,  0.67465753])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "NB_bow = MultinomialNB()\n",
    "NB_bow_fit = NB_bow.fit( train_data_features, raw[\"Sentiment\"] )\n",
    "scores5 = cross_val_score(NB_bow_fit, train_data_features, raw[\"Sentiment\"], cv=5)\n",
    "scores5   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.54090909,  0.50681818,  0.71590909,  0.78181818,  0.69020501,\n",
       "        0.74715262,  0.68792711,  0.73972603,  0.69107551,  0.75286041])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores10 = cross_val_score(NB_bow_fit, train_data_features, raw[\"Sentiment\"], cv=10)\n",
    "scores10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 5cv : 0.63 (+/- 0.21)\n",
      "Accuracy 10cv : 0.69 (+/- 0.17)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy 5cv : %0.2f (+/- %0.2f)\" % (scores5.mean(), scores5.std() * 2))\n",
    "print(\"Accuracy 10cv : %0.2f (+/- %0.2f)\" % (scores10.mean(), scores10.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOF + Logistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.47554039,  0.67007964,  0.69362187,  0.69897377,  0.6826484 ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_bow_fit = LR()\n",
    "LR_bow_fit = LR_bow_fit.fit( train_data_features, raw[\"Sentiment\"] )\n",
    "scores5 = cross_val_score(LR_bow_fit, train_data_features, raw[\"Sentiment\"], cv=5)\n",
    "scores5   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.60681818,  0.58636364,  0.74090909,  0.71818182,  0.67653759,\n",
       "        0.74943052,  0.71070615,  0.7283105 ,  0.73913043,  0.75057208])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores10 = cross_val_score(LR_bow_fit, train_data_features, raw[\"Sentiment\"], cv=10)\n",
    "scores10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 5cv : 0.64 (+/- 0.17)\n",
      "Accuracy 10cv : 0.70 (+/- 0.11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy 5cv : %0.2f (+/- %0.2f)\" % (scores5.mean(), scores5.std() * 2))\n",
    "print(\"Accuracy 10cv : %0.2f (+/- %0.2f)\" % (scores10.mean(), scores10.std() * 2))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Anaconda Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
